# LibreStorien - Test de Grand ModÃ¨le de Langage 

## ğŸ“¦ PrÃ©sentation

**LibreStorien** est un projet permettant de tester des GML sur diffÃ©rents critÃ¨res prÃ©dÃ©finis. Il s'inscrit dans un projet proposÃ© par API et Montpel'Libre. 

Le test des GML peut s'effectuer en local ou par API. 

# Test en Local

Dans ce rÃ©positoire vous trouvez des scripts permettant de :
- PrÃ©parer un environnement de test pour des modÃ¨les dâ€™IA locaux via **Ollama**
- Lancer automatiquement des tests Ã  partir de fichiers contenant des prompts

Lâ€™objectif est de faciliter les tests de modÃ¨les IA (comme `llama3`, `mistral`, etc.) avec une sÃ©rie de questions, et de stocker les rÃ©ponses dans un fichier de sortie propre.

---

## ğŸ“ Contenu des scripts

### 1. `LibreStorien_Initialisation.sh`

Ce script prÃ©pare lâ€™environnement nÃ©cessaire :

- CrÃ©e le dossier `Prompt/` avec un fichier de test `1er_prompt.txt` contenant 4 questions types
- CrÃ©e le dossier `DATA_Rep/` pour stocker les rÃ©ponses gÃ©nÃ©rÃ©es
- VÃ©rifie si le logiciel **Ollama** est installÃ© :
  - Si oui, vÃ©rifie qu'il est Ã  jour (comparaison avec la derniÃ¨re version sur GitHub)
  - Si non, propose de lâ€™installer automatiquement (Linux ou macOS)
- VÃ©rifie Ã©galement si le module `jq` est prÃ©sent (utilisÃ© pour lire l'API GitHub)

---

### 2. `LibreStorien_TestIA.sh`

Ce script permet de tester un modÃ¨le IA local :

1. Demande Ã  l'utilisateur :
   - Le nom du modÃ¨le Ollama Ã  tester (`llama3`, `mistral`, etc.)
   - Un fichier `.txt` contenant des prompts (dans le dossier `Prompt/`)
   - Un prompt par ligne dans le document donnÃ©
   - Le nom du fichier `.txt` de sauvegarde (dans `DATA_Rep/`)

2. VÃ©rifie que :
   - Le modÃ¨le est bien installÃ© (sinon propose de le tÃ©lÃ©charger)
   - Le fichier de prompt est valide (existant et `.txt`)
   - Le nom du fichier de sauvegarde ne contient pas de caractÃ¨res interdits

3. Pour chaque ligne du fichier de prompt :
   - Envoie le texte au modÃ¨le Ollama
   - Enregistre la rÃ©ponse dans le fichier de sortie, avec des sÃ©parateurs lisibles

---

## âœ… PrÃ©requis

Avant de lancer les scripts, assure-toi dâ€™avoir :

- **Ollama** installÃ© : [https://ollama.com/](https://ollama.com/)
- Un modÃ¨le dÃ©jÃ  tÃ©lÃ©chargÃ© via `ollama pull <nom_du_modÃ¨le>`
- Le module `jq` installÃ© (`sudo apt install jq` ou `brew install jq`)
- Une connexion Internet pour tÃ©lÃ©charger/mettre Ã  jour si nÃ©cessaire

---

## ğŸš€ Lancement

1. **Initialiser lâ€™environnement** (Ã  faire une seule fois) :
   ```
   bash ./LibreStorien_Installation.sh
   ```

2. **Lancer un test IA** :
   ```
   bash ./LibreStorien_TestIA.sh
   ```

---

## ğŸ§ª Exemple de prompt (dans Prompt/1er_prompt.txt)

```
Quelle est votre couleur prÃ©fÃ©rÃ©e ?
Quel est votre animal prÃ©fÃ©rÃ© ?
D'oÃ¹ venez-vous ?
Quel est votre plat prÃ©fÃ©rÃ© ?
```
Dans le fichier prompt vous trouverez l'intÃ©gralitÃ© de nos datasets. Ces questions ont Ã©tÃ© choisies dans des buts d'Ã©valuation prÃ©cise. Pour plus d'informations vous pouvez-vous rÃ©fÃ©rer Ã  notre rapport : . 
---

## ğŸ“‚ Organisation attendue des fichiers

```
LibreStorien/
â”œâ”€â”€ Prompt/
â”‚   â””â”€â”€ 1er_prompt.txt
â”œâ”€â”€ DATA_Rep/
â”‚   â””â”€â”€ <fichiers de rÃ©ponses>.txt
â”œâ”€â”€ LibreStorien_Installation.sh
â”œâ”€â”€ LibreStorien_TestIA.sh
â””â”€â”€ README.md
```

---

## ğŸ” Remarques

- Le script ne vÃ©rifie pas les droits d'Ã©criture dans les dossiers : lance-le avec un utilisateur ayant les bons droits.
- En cas dâ€™erreur de tÃ©lÃ©chargement du modÃ¨le ou problÃ¨me rÃ©seau, relance simplement le script.

---
---
# Test via API 

Pour utiliser notre mÃ©thode de test par API, vous avez accÃ¨s Ã  un fichier **Test_EPF.sh**.

Dans ce fichier vous retrouverez des commande permettant de 'pull' un modÃ¨le sur votre serveur. (ligne 34)
Assurez vous de bien l'avoir installÃ©, le programme ne le fait pas automatiquement pour Ã©viter de surcharger le serveur.
---
PULL_MODEL="curl -s http://${OLLAMA_IP}:11434/api/pull -d '{\"model\": \"${MODEL}\"}'"
---

Vous devez Ã©galement modifier le fichier, afin de rentrer l'adresse IP de votre serveur **Ollama**. (ligne 20) 
---
OLLAMA_IP=
---

! Pensez Ã  aussi modifier le nom du modÃ¨le que vous souhaitez tester ! 
---

## âœ¨ Auteur

**DURAND Corentin**
**BROSSE Axelle**
Date : *Avril 2025*
