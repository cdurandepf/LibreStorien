# LibreStorien - Test de Grand Mod√®le de Langage 

## üì¶ Pr√©sentation

**LibreStorien** est un projet permettant de tester des GML sur diff√©rents crit√®res pr√©d√©finis. Il s'inscrit dans un projet propos√© par API et Montpel'Libre. 

Ce travail est sous licence CC-by-SA.4.0.![t√©l√©chargement](https://github.com/user-attachments/assets/e246e182-81a4-40c2-b5b5-9ac4ecf256a3)


Le test des GML peut s'effectuer en local ou par API. 

# Test en Local

Dans ce r√©positoire vous trouvez des scripts permettant de :
- Pr√©parer un environnement de test pour des mod√®les d‚ÄôIA locaux via **Ollama**
- Lancer automatiquement des tests √† partir de fichiers contenant des prompts

L‚Äôobjectif est de faciliter les tests de mod√®les IA (comme `llama3`, `mistral`, etc.) avec une s√©rie de questions, et de stocker les r√©ponses dans un fichier de sortie propre.

---

## üìÅ Contenu des scripts

### 1. `LibreStorien_Initialisation.sh`

Ce script pr√©pare l‚Äôenvironnement n√©cessaire :

- Cr√©e le dossier `Prompt/` avec un fichier de test `1er_prompt.txt` contenant 4 questions types
- Cr√©e le dossier `DATA_Rep/` pour stocker les r√©ponses g√©n√©r√©es
- V√©rifie si le logiciel **Ollama** est install√© :
  - Si oui, v√©rifie qu'il est √† jour (comparaison avec la derni√®re version sur GitHub)
  - Si non, propose de l‚Äôinstaller automatiquement (Linux ou macOS)
- V√©rifie √©galement si le module `jq` est pr√©sent (utilis√© pour lire l'API GitHub)

---

### 2. `LibreStorien_TestIA.sh`

Ce script permet de tester un mod√®le IA local :

1. Demande √† l'utilisateur :
   - Le nom du mod√®le Ollama √† tester (`llama3`, `mistral`, etc.)
   - Un fichier `.txt` contenant des prompts (dans le dossier `Prompt/`)
   - Un prompt par ligne dans le document donn√©
   - Le nom du fichier `.txt` de sauvegarde (dans `DATA_Rep/`)

2. V√©rifie que :
   - Le mod√®le est bien install√© (sinon propose de le t√©l√©charger)
   - Le fichier de prompt est valide (existant et `.txt`)
   - Le nom du fichier de sauvegarde ne contient pas de caract√®res interdits

3. Pour chaque ligne du fichier de prompt :
   - Envoie le texte au mod√®le Ollama
   - Enregistre la r√©ponse dans le fichier de sortie, avec des s√©parateurs lisibles

---

## ‚úÖ Pr√©requis

Avant de lancer les scripts, assure-toi d‚Äôavoir :

- **Ollama** install√© : [https://ollama.com/](https://ollama.com/)
- Un mod√®le d√©j√† t√©l√©charg√© via `ollama pull <nom_du_mod√®le>`
- Le module `jq` install√© (`sudo apt install jq` ou `brew install jq`)
- Une connexion Internet pour t√©l√©charger/mettre √† jour si n√©cessaire

---

## üöÄ Lancement

1. **Initialiser l‚Äôenvironnement** (√† faire une seule fois) :
   ```
   bash ./LibreStorien_Installation.sh
   ```

2. **Lancer un test IA** :
   ```
   bash ./LibreStorien_TestIA.sh
   ```

---

## üß™ Exemple de prompt (dans Prompt/1er_prompt.txt)

```
Quelle est votre couleur pr√©f√©r√©e ?
Quel est votre animal pr√©f√©r√© ?
D'o√π venez-vous ?
Quel est votre plat pr√©f√©r√© ?
```
Dans le fichier prompt vous trouverez l'int√©gralit√© de nos datasets. Ces questions ont √©t√© choisies dans des buts d'√©valuation pr√©cise. Pour plus d'informations vous pouvez-vous r√©f√©rer √† notre rapport : . 
---

## üìÇ Organisation attendue des fichiers

```
LibreStorien/
‚îú‚îÄ‚îÄ Prompt/
‚îÇ   ‚îî‚îÄ‚îÄ 1er_prompt.txt
‚îú‚îÄ‚îÄ DATA_Rep/
‚îÇ   ‚îî‚îÄ‚îÄ <fichiers de r√©ponses>.txt
‚îú‚îÄ‚îÄ LibreStorien_Installation.sh
‚îú‚îÄ‚îÄ LibreStorien_TestIA.sh
‚îî‚îÄ‚îÄ README.md
```

---

## üîê Remarques

- Le script ne v√©rifie pas les droits d'√©criture dans les dossiers : lance-le avec un utilisateur ayant les bons droits.
- En cas d‚Äôerreur de t√©l√©chargement du mod√®le ou probl√®me r√©seau, relance simplement le script.

---
---
# Test via API 

Pour utiliser notre m√©thode de test par API, vous avez acc√®s √† un fichier **Test_EPF.sh**.

Dans ce fichier vous retrouverez des commande permettant de 'pull' un mod√®le sur votre serveur. (ligne 34)
Assurez vous de bien l'avoir install√©, le programme ne le fait pas automatiquement pour √©viter de surcharger le serveur.

```
PULL_MODEL="curl -s http://${OLLAMA_IP}:11434/api/pull -d '{\"model\": \"${MODEL}\"}'"
```

Vous devez √©galement modifier le fichier, afin de rentrer l'adresse IP de votre serveur **Ollama**. (ligne 20) 

```
OLLAMA_IP=
```

! Pensez √† aussi modifier le nom du mod√®le que vous souhaitez tester ! 

Une fois les modifications effectu√©es vous pouvez lancer le programme 

---

## ‚ú® Auteur

**DURAND Corentin**
**BROSSE Axelle**
Date : *Avril 2025*
